{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Forecasting with Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook is a Work In Progress, there may be a couple of mistakes, I'll clean the code and improve the explanations soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Contents**\n",
    "\n",
    "- **EDA** - A brief EDA, showing the essentials\n",
    "- **Aggregating Categorical Variables** - A continuation of the EDA, showing that we should be able to forecast the aggregated time series (daily total sales) and then disaggregate the forecasts based on historical proportions and other data without penalising performance.\n",
    "- **Total Sales Forecast** - Forecast the total number of sales across all categorical variables using Linear Regression for 2017, 2018 and 2019.\n",
    "- **Product Sales Ratio Forecast** - Forecast the ratio of sales between products for 2017, 2018 and 2019.\n",
    "- **Dissagregating Total Sales Forecast** - Disagreggate the Total Sales forecasts, to get the forecast for each categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is based off my notebook from Season 2, on a similar competition:\n",
    "\n",
    "- https://www.kaggle.com/code/cabaxiom/tps-sep-22-eda-and-linear-regression-baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preliminaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:42.913329Z",
     "iopub.status.busy": "2025-01-03T00:55:42.912818Z",
     "iopub.status.idle": "2025-01-03T00:55:42.919839Z",
     "shell.execute_reply": "2025-01-03T00:55:42.91861Z",
     "shell.execute_reply.started": "2025-01-03T00:55:42.913291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:42.922313Z",
     "iopub.status.busy": "2025-01-03T00:55:42.921929Z",
     "iopub.status.idle": "2025-01-03T00:55:43.263339Z",
     "shell.execute_reply": "2025-01-03T00:55:43.261986Z",
     "shell.execute_reply.started": "2025-01-03T00:55:42.922277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/onyxia/work/Forecasting_Sticker_Sales/train.csv\", parse_dates=[\"date\"])\n",
    "original_train_df = train_df.copy()\n",
    "test_df = pd.read_csv(\"/home/onyxia/work/Forecasting_Sticker_Sales/test.csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:43.265885Z",
     "iopub.status.busy": "2025-01-03T00:55:43.265569Z",
     "iopub.status.idle": "2025-01-03T00:55:43.288461Z",
     "shell.execute_reply": "2025-01-03T00:55:43.287217Z",
     "shell.execute_reply.started": "2025-01-03T00:55:43.265858Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date country              store            product  num_sold\n",
       "0   0 2010-01-01  Canada  Discount Stickers  Holographic Goose       NaN\n",
       "1   1 2010-01-01  Canada  Discount Stickers             Kaggle     973.0\n",
       "2   2 2010-01-01  Canada  Discount Stickers       Kaggle Tiers     906.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230130</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230131</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230132</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       date country              store            product\n",
       "0  230130 2017-01-01  Canada  Discount Stickers  Holographic Goose\n",
       "1  230131 2017-01-01  Canada  Discount Stickers             Kaggle\n",
       "2  230132 2017-01-01  Canada  Discount Stickers       Kaggle Tiers"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head(3))\n",
    "display(test_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- There are 3 categorical columns that together describe a univariate time series. Country, Store and Product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which countries, stores and products we have data for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:43.290211Z",
     "iopub.status.busy": "2025-01-03T00:55:43.289868Z",
     "iopub.status.idle": "2025-01-03T00:55:43.298593Z",
     "shell.execute_reply": "2025-01-03T00:55:43.297429Z",
     "shell.execute_reply.started": "2025-01-03T00:55:43.29018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def val_count_df(df, column_name, sort_by_column_name=False):\n",
    "    value_count = df[column_name].value_counts().reset_index().rename(columns={column_name:\"Value Count\",\"index\":column_name}).set_index(column_name)\n",
    "    value_count[\"Percentage\"] = df[column_name].value_counts(normalize=True)*100\n",
    "    value_count = value_count.reset_index()\n",
    "    if sort_by_column_name:\n",
    "        value_count = value_count.sort_values(column_name)\n",
    "    return value_count\n",
    "\n",
    "\n",
    "\n",
    "def plot_and_display_valuecounts(df, column_name, sort_by_column_name=False):\n",
    "    val_count = val_count_df(df, column_name, sort_by_column_name)\n",
    "    #display(val_count)\n",
    "    val_count.set_index(column_name).plot.pie(y=\"Value Count\", figsize=(5,5), legend=False, ylabel=\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>491.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date country              store             product  num_sold\n",
       "0   0 2010-01-01  Canada  Discount Stickers   Holographic Goose       NaN\n",
       "1   1 2010-01-01  Canada  Discount Stickers              Kaggle     973.0\n",
       "2   2 2010-01-01  Canada  Discount Stickers        Kaggle Tiers     906.0\n",
       "3   3 2010-01-01  Canada  Discount Stickers            Kerneler     423.0\n",
       "4   4 2010-01-01  Canada  Discount Stickers  Kerneler Dark Mode     491.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:43.302575Z",
     "iopub.status.busy": "2025-01-03T00:55:43.302069Z",
     "iopub.status.idle": "2025-01-03T00:55:43.494316Z",
     "shell.execute_reply": "2025-01-03T00:55:43.492304Z",
     "shell.execute_reply.started": "2025-01-03T00:55:43.302528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['country'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41103/551579229.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_and_display_valuecounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'country'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_41103/2289224205.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, column_name, sort_by_column_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_and_display_valuecounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_by_column_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mval_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_count_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_by_column_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#display(val_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mval_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Value Count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_41103/2289224205.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, column_name, sort_by_column_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mval_count_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_by_column_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvalue_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Value Count\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalue_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Percentage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalue_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msort_by_column_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6118\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mNone of \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m are in the columns\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['country'] are in the columns\""
     ]
    }
   ],
   "source": [
    "plot_and_display_valuecounts(train_df, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:43.497285Z",
     "iopub.status.busy": "2025-01-03T00:55:43.496766Z",
     "iopub.status.idle": "2025-01-03T00:55:43.682638Z",
     "shell.execute_reply": "2025-01-03T00:55:43.681036Z",
     "shell.execute_reply.started": "2025-01-03T00:55:43.497239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_and_display_valuecounts(train_df, \"store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:43.685741Z",
     "iopub.status.busy": "2025-01-03T00:55:43.684372Z",
     "iopub.status.idle": "2025-01-03T00:55:43.887727Z",
     "shell.execute_reply": "2025-01-03T00:55:43.886348Z",
     "shell.execute_reply.started": "2025-01-03T00:55:43.685681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_and_display_valuecounts(train_df, \"product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:43.890039Z",
     "iopub.status.busy": "2025-01-03T00:55:43.88947Z",
     "iopub.status.idle": "2025-01-03T00:55:43.999449Z",
     "shell.execute_reply": "2025-01-03T00:55:43.998026Z",
     "shell.execute_reply.started": "2025-01-03T00:55:43.889983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "counts = train_df.groupby([\"country\",\"store\",\"product\"])[\"num_sold\"].count()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total we have **90 univariate time series** most of **length 2557**\n",
    "\n",
    "Taking a look at the ones without length 2557:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:44.001455Z",
     "iopub.status.busy": "2025-01-03T00:55:44.001053Z",
     "iopub.status.idle": "2025-01-03T00:55:44.011543Z",
     "shell.execute_reply": "2025-01-03T00:55:44.010217Z",
     "shell.execute_reply.started": "2025-01-03T00:55:44.001416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "missing_data = counts.loc[counts != 2557]\n",
    "missing_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total 9 of the 90 time series is missing some data.\n",
    "\n",
    "Lets take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:55:44.013681Z",
     "iopub.status.busy": "2025-01-03T00:55:44.013337Z",
     "iopub.status.idle": "2025-01-03T00:56:05.764499Z",
     "shell.execute_reply": "2025-01-03T00:56:05.763229Z",
     "shell.execute_reply.started": "2025-01-03T00:55:44.013651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f,axs = plt.subplots(9,1, figsize=(20,50))\n",
    "for i, (country, store, product) in enumerate(missing_data.index):\n",
    "    plot_df = train_df.loc[(train_df[\"country\"] == country) & (train_df[\"store\"] == store) & (train_df[\"product\"] == product)]\n",
    "    missing_vals = plot_df.loc[plot_df[\"num_sold\"].isna()]\n",
    "    sns.lineplot(data=plot_df, x=\"date\", y=\"num_sold\", ax=axs[i])\n",
    "    for missing_date in missing_vals[\"date\"]:\n",
    "        axs[i].axvline(missing_date, color='red',  linestyle='-', linewidth=1, alpha=0.2)\n",
    "    axs[i].set_title(f\"{country} - {store} - {product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Looks to me like data is missing when the value for num_sold < 200 for Canada and < 5 for Kenya (for most the time series). We could impute based on that assumption, but I've used a different method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Time series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:05.768657Z",
     "iopub.status.busy": "2025-01-03T00:56:05.768266Z",
     "iopub.status.idle": "2025-01-03T00:56:05.779388Z",
     "shell.execute_reply": "2025-01-03T00:56:05.778218Z",
     "shell.execute_reply.started": "2025-01-03T00:56:05.768625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Train - Earliest date:\", train_df[\"date\"].min())\n",
    "print(\"Train - Latest date:\", train_df[\"date\"].max())\n",
    "\n",
    "print(\"Test - Earliest date:\", test_df[\"date\"].min())\n",
    "print(\"Test - Latest date:\", test_df[\"date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have **7 years** of data **from 2010-01-01 to 2016-12-31** to train occuring at **daily frequency**.\n",
    "- We are required to forecast 3 year of data, **from 2017-01-01 to 2019-12-31**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:05.781615Z",
     "iopub.status.busy": "2025-01-03T00:56:05.781094Z",
     "iopub.status.idle": "2025-01-03T00:56:05.936772Z",
     "shell.execute_reply": "2025-01-03T00:56:05.93547Z",
     "shell.execute_reply.started": "2025-01-03T00:56:05.781562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weekly_df = train_df.groupby([\"country\",\"store\", \"product\", pd.Grouper(key=\"date\", freq=\"W\")])[\"num_sold\"].sum().rename(\"num_sold\").reset_index()\n",
    "monthly_df = train_df.groupby([\"country\",\"store\", \"product\", pd.Grouper(key=\"date\", freq=\"MS\")])[\"num_sold\"].sum().rename(\"num_sold\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:05.938837Z",
     "iopub.status.busy": "2025-01-03T00:56:05.938405Z",
     "iopub.status.idle": "2025-01-03T00:56:05.946329Z",
     "shell.execute_reply": "2025-01-03T00:56:05.94499Z",
     "shell.execute_reply.started": "2025-01-03T00:56:05.938793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_all(df):\n",
    "    f,axes = plt.subplots(3,2,figsize=(20,30), sharex = True, sharey=True)\n",
    "    f.tight_layout()\n",
    "    for n,prod in enumerate(df[\"product\"].unique()):\n",
    "        plot_df = df.loc[df[\"product\"] == prod]\n",
    "        sns.lineplot(data=plot_df, x=\"date\", y=\"num_sold\", hue=\"country\", style=\"store\",ax=axes[n//2,n%2])\n",
    "        axes[n//2,n%2].set_title(\"Product: \"+str(prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:05.948183Z",
     "iopub.status.busy": "2025-01-03T00:56:05.947746Z",
     "iopub.status.idle": "2025-01-03T00:56:09.951191Z",
     "shell.execute_reply": "2025-01-03T00:56:09.949963Z",
     "shell.execute_reply.started": "2025-01-03T00:56:05.948117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_all(weekly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:09.953286Z",
     "iopub.status.busy": "2025-01-03T00:56:09.952869Z",
     "iopub.status.idle": "2025-01-03T00:56:13.253422Z",
     "shell.execute_reply": "2025-01-03T00:56:13.252093Z",
     "shell.execute_reply.started": "2025-01-03T00:56:09.95325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_all(monthly_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Aggregating Time Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to show that its a good idea to aggregate the time series across each of the three categorical variables: Store, Country and Product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test to see if the pattern between stores is the same, regardless of product or country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Country**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if the difference in countries, can be explained by a single constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:13.255302Z",
     "iopub.status.busy": "2025-01-03T00:56:13.254947Z",
     "iopub.status.idle": "2025-01-03T00:56:14.359211Z",
     "shell.execute_reply": "2025-01-03T00:56:14.357845Z",
     "shell.execute_reply.started": "2025-01-03T00:56:13.25527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "country_weights = train_df.groupby(\"country\")[\"num_sold\"].sum()/train_df[\"num_sold\"].sum()\n",
    "\n",
    "country_ratio_over_time = (train_df.groupby([\"date\",\"country\"])[\"num_sold\"].sum() / train_df.groupby([\"date\"])[\"num_sold\"].sum()).reset_index()\n",
    "f,ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data = country_ratio_over_time, x=\"date\", y=\"num_sold\", hue=\"country\");\n",
    "ax.set_ylabel(\"Proportion of sales\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- The lines are not perflectly straight, with rises and falls each year (noteably exactly at the year markings) something artificially strange is going on here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link seems to be GDP per captia, credit to [@siukeitin](https://www.kaggle.com/siukeitin) for discovering this in this discussion thread https://www.kaggle.com/competitions/playground-series-s5e1/discussion/554349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:14.361431Z",
     "iopub.status.busy": "2025-01-03T00:56:14.360974Z",
     "iopub.status.idle": "2025-01-03T00:56:15.505795Z",
     "shell.execute_reply": "2025-01-03T00:56:15.50442Z",
     "shell.execute_reply.started": "2025-01-03T00:56:14.361386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gdp_per_capita_df = pd.read_csv(\"/home/onyxia/work/Forecasting_Sticker_Sales/GDP/gdp_per_capita.csv\")\n",
    "\n",
    "years =  [\"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "gdp_per_capita_filtered_df = gdp_per_capita_df.loc[gdp_per_capita_df[\"Country Name\"].isin(train_df[\"country\"].unique()), [\"Country Name\"] + years].set_index(\"Country Name\")\n",
    "gdp_per_capita_filtered_df[\"2010_ratio\"] = gdp_per_capita_filtered_df[\"2010\"] / gdp_per_capita_filtered_df.sum()[\"2010\"]\n",
    "for year in years:\n",
    "    gdp_per_capita_filtered_df[f\"{year}_ratio\"] = gdp_per_capita_filtered_df[year] / gdp_per_capita_filtered_df.sum()[year]\n",
    "gdp_per_capita_filtered_ratios_df = gdp_per_capita_filtered_df[[i+\"_ratio\" for i in years]]\n",
    "gdp_per_capita_filtered_ratios_df.columns = [int(i) for i in years]\n",
    "gdp_per_capita_filtered_ratios_df = gdp_per_capita_filtered_ratios_df.unstack().reset_index().rename(columns = {\"level_0\": \"year\", 0: \"ratio\", \"Country Name\": \"country\"})\n",
    "gdp_per_capita_filtered_ratios_df['year'] = pd.to_datetime(gdp_per_capita_filtered_ratios_df['year'], format='%Y')\n",
    "\n",
    "# For plotting purposes\n",
    "gdp_per_capita_filtered_ratios_df_2 = gdp_per_capita_filtered_ratios_df.copy()\n",
    "gdp_per_capita_filtered_ratios_df_2[\"year\"] = pd.to_datetime(gdp_per_capita_filtered_ratios_df_2['year'].astype(str)) + pd.offsets.YearEnd(1)\n",
    "gdp_per_capita_filtered_ratios_df = pd.concat([gdp_per_capita_filtered_ratios_df, gdp_per_capita_filtered_ratios_df_2]).reset_index()\n",
    "\n",
    "f,ax = plt.subplots(figsize=(20,20))\n",
    "sns.lineplot(data = country_ratio_over_time, x=\"date\", y=\"num_sold\", hue=\"country\");\n",
    "sns.lineplot(data = gdp_per_capita_filtered_ratios_df, x=\"year\", y = \"ratio\", hue=\"country\", palette = [\"black\"]*6, legend = False)\n",
    "ax.set_ylabel(\"Proportion of sales\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Note that Canada and Kenya do not perfectly allign to these ratios, likely because of missing values.\n",
    "\n",
    "**Insight:**\n",
    "- This means we can perfectly predict the proportion of sales for each country for each year, by considering the annual GDP per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:15.508006Z",
     "iopub.status.busy": "2025-01-03T00:56:15.507594Z",
     "iopub.status.idle": "2025-01-03T00:56:15.515567Z",
     "shell.execute_reply": "2025-01-03T00:56:15.514207Z",
     "shell.execute_reply.started": "2025-01-03T00:56:15.507961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gdp_per_capita_filtered_ratios_df_2[\"year\"] = gdp_per_capita_filtered_ratios_df_2[\"year\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:15.517588Z",
     "iopub.status.busy": "2025-01-03T00:56:15.517258Z",
     "iopub.status.idle": "2025-01-03T00:56:15.531765Z",
     "shell.execute_reply": "2025-01-03T00:56:15.530521Z",
     "shell.execute_reply.started": "2025-01-03T00:56:15.51756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_adjust_country(df):\n",
    "    new_df = df.copy()\n",
    "    new_df[\"year\"] = new_df[\"date\"].dt.year\n",
    "    \n",
    "    for country in new_df[\"country\"].unique():\n",
    "        for year in new_df[\"year\"].unique():\n",
    "            new_df.loc[(new_df[\"country\"] == country) & (new_df[\"year\"] == year), \"num_sold\"] = new_df.loc[(new_df[\"country\"] == country) & (new_df[\"year\"] == year), \"num_sold\"] / gdp_per_capita_filtered_ratios_df_2.loc[(gdp_per_capita_filtered_ratios_df_2[\"country\"] == country) & (gdp_per_capita_filtered_ratios_df_2[\"year\"] == year), \"ratio\"].values[0]\n",
    "            \n",
    "    plot_all(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:15.533307Z",
     "iopub.status.busy": "2025-01-03T00:56:15.532963Z",
     "iopub.status.idle": "2025-01-03T00:56:19.32597Z",
     "shell.execute_reply": "2025-01-03T00:56:19.324784Z",
     "shell.execute_reply.started": "2025-01-03T00:56:15.533278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_adjust_country(monthly_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- With the exception of Kenya and sometimes Canada (because of the missing values) the number of sales overlap well for each store and product!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this information for imputation of the missing values (including the completely missing time series) by looking at sales from the same product and some store but for differnt countries, and using the applied ratios to guess what the missing values would have been."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:19.328012Z",
     "iopub.status.busy": "2025-01-03T00:56:19.327672Z",
     "iopub.status.idle": "2025-01-03T00:56:24.407788Z",
     "shell.execute_reply": "2025-01-03T00:56:24.406277Z",
     "shell.execute_reply.started": "2025-01-03T00:56:19.327981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_imputed = train_df.copy()\n",
    "print(f\"Missing values remaining: {train_df_imputed['num_sold'].isna().sum()}\")\n",
    "\n",
    "train_df_imputed[\"year\"] = train_df_imputed[\"date\"].dt.year\n",
    "for year in train_df_imputed[\"year\"].unique():\n",
    "    # Impute Time Series 1 (Canada, Discount Stickers, Holographic Goose)\n",
    "    target_ratio = gdp_per_capita_filtered_ratios_df_2.loc[(gdp_per_capita_filtered_ratios_df_2[\"year\"] == year) & (gdp_per_capita_filtered_ratios_df_2[\"country\"] == \"Norway\"), \"ratio\"].values[0] # Using Norway as should have the best precision\n",
    "    current_raito = gdp_per_capita_filtered_ratios_df_2.loc[(gdp_per_capita_filtered_ratios_df_2[\"year\"] == year) & (gdp_per_capita_filtered_ratios_df_2[\"country\"] == \"Canada\"), \"ratio\"].values[0]\n",
    "    ratio_can = current_raito / target_ratio\n",
    "    train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Canada\") & (train_df_imputed[\"store\"] == \"Discount Stickers\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] = (train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Norway\") & (train_df_imputed[\"store\"] == \"Discount Stickers\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] * ratio_can).values\n",
    "    \n",
    "    # Going to be a bit risky and completely replace a couple of stores for Canada with a lot of missing data with Norways data:\n",
    "    train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Canada\") & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] = (train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Norway\") & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] * ratio_can).values\n",
    "    train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Canada\") & (train_df_imputed[\"store\"] == \"Stickers for Less\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] = (train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Norway\") & (train_df_imputed[\"store\"] == \"Stickers for Less\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] * ratio_can).values\n",
    "    \n",
    "    # Impute Time Series 1 (Kenya, Discount Stickers, Holographic Goose)\n",
    "    current_raito = gdp_per_capita_filtered_ratios_df_2.loc[(gdp_per_capita_filtered_ratios_df_2[\"year\"] == year) & (gdp_per_capita_filtered_ratios_df_2[\"country\"] == \"Kenya\"), \"ratio\"].values[0]\n",
    "    ratio_ken = current_raito / target_ratio\n",
    "    train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Kenya\") & (train_df_imputed[\"store\"] == \"Discount Stickers\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] = (train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Norway\") & (train_df_imputed[\"store\"] == \"Discount Stickers\") & (train_df_imputed[\"product\"] == \"Holographic Goose\")& (train_df_imputed[\"year\"] == year), \"num_sold\"] * ratio_ken).values\n",
    "\n",
    "    # Going to be a bit risky and completely replace a couple of stores for Kenya with a lot of missing data with Norways data:\n",
    "    train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Kenya\") & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] = (train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Norway\") & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] * ratio_ken).values\n",
    "    train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Kenya\") & (train_df_imputed[\"store\"] == \"Stickers for Less\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] = (train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Norway\") & (train_df_imputed[\"store\"] == \"Stickers for Less\") & (train_df_imputed[\"product\"] == \"Holographic Goose\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] * ratio_ken).values\n",
    "    train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Kenya\") & (train_df_imputed[\"store\"] == \"Discount Stickers\") & (train_df_imputed[\"product\"] == \"Kerneler\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] = (train_df_imputed.loc[(train_df_imputed[\"country\"] == \"Norway\") & (train_df_imputed[\"store\"] == \"Discount Stickers\") & (train_df_imputed[\"product\"] == \"Kerneler\") & (train_df_imputed[\"year\"] == year), \"num_sold\"] * ratio_ken).values\n",
    "    \n",
    "print(f\"Missing values remaining: {train_df_imputed['num_sold'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems a bit overkill to replace the entire timeseries for the remaining 2 missing values, I'll just fill them in manually using the graphs from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:24.409875Z",
     "iopub.status.busy": "2025-01-03T00:56:24.409427Z",
     "iopub.status.idle": "2025-01-03T00:56:24.439416Z",
     "shell.execute_reply": "2025-01-03T00:56:24.438116Z",
     "shell.execute_reply.started": "2025-01-03T00:56:24.40982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "missing_rows = train_df_imputed.loc[train_df_imputed[\"num_sold\"].isna()]\n",
    "display(missing_rows)\n",
    "train_df_imputed.loc[train_df_imputed[\"id\"] == 23719, \"num_sold\"] = 4\n",
    "train_df_imputed.loc[train_df_imputed[\"id\"] == 207003, \"num_sold\"] = 195\n",
    "\n",
    "print(f\"Missing values remaining: {train_df_imputed['num_sold'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:24.441349Z",
     "iopub.status.busy": "2025-01-03T00:56:24.440874Z",
     "iopub.status.idle": "2025-01-03T00:56:24.59384Z",
     "shell.execute_reply": "2025-01-03T00:56:24.592543Z",
     "shell.execute_reply.started": "2025-01-03T00:56:24.441305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weekly_df = train_df_imputed.groupby([\"country\",\"store\", \"product\", pd.Grouper(key=\"date\", freq=\"W\")])[\"num_sold\"].sum().rename(\"num_sold\").reset_index()\n",
    "monthly_df = train_df_imputed.groupby([\"country\",\"store\", \"product\", pd.Grouper(key=\"date\", freq=\"MS\")])[\"num_sold\"].sum().rename(\"num_sold\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Store**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test to see if the pattern between stores is the same, regardless of product or country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:24.596109Z",
     "iopub.status.busy": "2025-01-03T00:56:24.59565Z",
     "iopub.status.idle": "2025-01-03T00:56:24.627356Z",
     "shell.execute_reply": "2025-01-03T00:56:24.6261Z",
     "shell.execute_reply.started": "2025-01-03T00:56:24.596066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "store_weights = train_df_imputed.groupby(\"store\")[\"num_sold\"].sum()/train_df_imputed[\"num_sold\"].sum()\n",
    "store_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:24.629481Z",
     "iopub.status.busy": "2025-01-03T00:56:24.629007Z",
     "iopub.status.idle": "2025-01-03T00:56:25.442664Z",
     "shell.execute_reply": "2025-01-03T00:56:25.441446Z",
     "shell.execute_reply.started": "2025-01-03T00:56:24.629434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "store_ratio_over_time = (train_df_imputed.groupby([\"date\",\"store\"])[\"num_sold\"].sum() / train_df_imputed.groupby([\"date\"])[\"num_sold\"].sum()).reset_index()\n",
    "f,ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data = store_ratio_over_time, x=\"date\", y=\"num_sold\", hue=\"store\");\n",
    "ax.set_ylabel(\"Proportion of sales\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:25.444887Z",
     "iopub.status.busy": "2025-01-03T00:56:25.444528Z",
     "iopub.status.idle": "2025-01-03T00:56:25.451434Z",
     "shell.execute_reply": "2025-01-03T00:56:25.45028Z",
     "shell.execute_reply.started": "2025-01-03T00:56:25.444854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_adjusted_store(df):\n",
    "    new_df = df.copy()\n",
    "    weights = store_weights.loc[\"Premium Sticker Mart\"] / store_weights\n",
    "    print(weights)\n",
    "    for store in weights.index:\n",
    "        new_df.loc[new_df[\"store\"] == store, \"num_sold\"] = new_df.loc[new_df[\"store\"] == store, \"num_sold\"] * weights[store]\n",
    "    plot_all(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the lines between stores overlap perfectly then trend and seasonality are not unique to the store and we can ignore its effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:25.453112Z",
     "iopub.status.busy": "2025-01-03T00:56:25.452778Z",
     "iopub.status.idle": "2025-01-03T00:56:28.745858Z",
     "shell.execute_reply": "2025-01-03T00:56:28.744836Z",
     "shell.execute_reply.started": "2025-01-03T00:56:25.453082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_adjusted_store(monthly_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- The dashed and solid lines representing the different stores overlap perfectly fore most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:**\n",
    "\n",
    "- This means we can perfectly predict the proportion of sales for each store, regardless of when it occurs.\n",
    "- Trend and seasonality are not unique to the store and we can ignore its effect. All differences in sales between stores can be explained by a single constant, which does not change over time.\n",
    "- This means we can forecast the store aggregated timeseries, and then disaggregating the forecasts based on historical proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Product**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product requires a different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:28.747841Z",
     "iopub.status.busy": "2025-01-03T00:56:28.7474Z",
     "iopub.status.idle": "2025-01-03T00:56:28.785446Z",
     "shell.execute_reply": "2025-01-03T00:56:28.784355Z",
     "shell.execute_reply.started": "2025-01-03T00:56:28.747798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "product_df = train_df_imputed.groupby([\"date\",\"product\"])[\"num_sold\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:28.791384Z",
     "iopub.status.busy": "2025-01-03T00:56:28.790884Z",
     "iopub.status.idle": "2025-01-03T00:56:29.772412Z",
     "shell.execute_reply": "2025-01-03T00:56:29.770785Z",
     "shell.execute_reply.started": "2025-01-03T00:56:28.79135Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data=product_df, x=\"date\", y=\"num_sold\", hue=\"product\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Product ratio for each date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:29.774273Z",
     "iopub.status.busy": "2025-01-03T00:56:29.773808Z",
     "iopub.status.idle": "2025-01-03T00:56:30.336848Z",
     "shell.execute_reply": "2025-01-03T00:56:30.335597Z",
     "shell.execute_reply.started": "2025-01-03T00:56:29.774232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "product_ratio_df = product_df.pivot(index=\"date\", columns=\"product\", values=\"num_sold\")\n",
    "product_ratio_df = product_ratio_df.apply(lambda x: x/x.sum(),axis=1)\n",
    "product_ratio_df = product_ratio_df.stack().rename(\"ratios\").reset_index()\n",
    "product_ratio_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:30.33885Z",
     "iopub.status.busy": "2025-01-03T00:56:30.33841Z",
     "iopub.status.idle": "2025-01-03T00:56:31.3163Z",
     "shell.execute_reply": "2025-01-03T00:56:31.31518Z",
     "shell.execute_reply.started": "2025-01-03T00:56:30.338806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data = product_ratio_df, x=\"date\", y=\"ratios\", hue=\"product\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The product ratio shows clear sinsidual lines for each product, with a period of 2 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "As we have a clear seasonal pattern of the ratio of sales for each product, we do not need to forecast each product individually (or treat product as a categorical variable etc.). Instead we can forecast the sum of all sales each day, then afterwards convert the forecasted sum down to the forecast for each product, using the forecasted **ratios** for each date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions** \n",
    "\n",
    "All this together means we only need to forecast 2 time series:\n",
    "1. The total sales each day\n",
    "2. The ratio in number of sales for each product each day\n",
    "\n",
    "We still need to be careful about some timeseries where we might not have sales, or missing data.\n",
    "\n",
    "\n",
    "Once we have completed the forecasts we can break the forecast down into the 3 categorical variables: Product, Country and Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Aggregated Time Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the aggregated time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:31.318115Z",
     "iopub.status.busy": "2025-01-03T00:56:31.317774Z",
     "iopub.status.idle": "2025-01-03T00:56:31.339561Z",
     "shell.execute_reply": "2025-01-03T00:56:31.337947Z",
     "shell.execute_reply.started": "2025-01-03T00:56:31.318077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "original_train_df_imputed = train_df_imputed.copy()\n",
    "train_df_imputed = train_df_imputed.groupby([\"date\"])[\"num_sold\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:31.341592Z",
     "iopub.status.busy": "2025-01-03T00:56:31.341228Z",
     "iopub.status.idle": "2025-01-03T00:56:31.97336Z",
     "shell.execute_reply": "2025-01-03T00:56:31.972217Z",
     "shell.execute_reply.started": "2025-01-03T00:56:31.341552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data = train_df_imputed, x=\"date\", y=\"num_sold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the time series we need to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:31.9753Z",
     "iopub.status.busy": "2025-01-03T00:56:31.974916Z",
     "iopub.status.idle": "2025-01-03T00:56:32.003934Z",
     "shell.execute_reply": "2025-01-03T00:56:32.002727Z",
     "shell.execute_reply.started": "2025-01-03T00:56:31.975268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weekly_df = train_df.groupby([pd.Grouper(key=\"date\", freq=\"W\")])[\"num_sold\"].sum().rename(\"num_sold\").reset_index()\n",
    "monthly_df = train_df.groupby([pd.Grouper(key=\"date\", freq=\"MS\")])[\"num_sold\"].sum().rename(\"num_sold\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:32.005985Z",
     "iopub.status.busy": "2025-01-03T00:56:32.005627Z",
     "iopub.status.idle": "2025-01-03T00:56:32.481785Z",
     "shell.execute_reply": "2025-01-03T00:56:32.480354Z",
     "shell.execute_reply.started": "2025-01-03T00:56:32.005954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20,9))\n",
    "sns.lineplot(data=monthly_df, x=\"date\", y=\"num_sold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:32.483714Z",
     "iopub.status.busy": "2025-01-03T00:56:32.483355Z",
     "iopub.status.idle": "2025-01-03T00:56:32.958995Z",
     "shell.execute_reply": "2025-01-03T00:56:32.957795Z",
     "shell.execute_reply.started": "2025-01-03T00:56:32.483682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20,9))\n",
    "sns.lineplot(data=weekly_df[1:-1], x=\"date\", y=\"num_sold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Seasonality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:32.961006Z",
     "iopub.status.busy": "2025-01-03T00:56:32.960568Z",
     "iopub.status.idle": "2025-01-03T00:56:32.971042Z",
     "shell.execute_reply": "2025-01-03T00:56:32.969886Z",
     "shell.execute_reply.started": "2025-01-03T00:56:32.960954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_seasonality(df, x_axis):\n",
    "    \n",
    "\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"day_of_year\"] = df['date'].apply(\n",
    "        lambda x: x.timetuple().tm_yday if not (x.is_leap_year and x.month > 2) else x.timetuple().tm_yday - 1\n",
    "    )\n",
    "\n",
    "    f,ax = plt.subplots(1,1,figsize=(20,8))\n",
    "    sns.lineplot(data=df, x=x_axis, y=\"num_sold\", ax=ax);\n",
    "    ax.set_title(\"{} Seasonality\".format(x_axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:32.973066Z",
     "iopub.status.busy": "2025-01-03T00:56:32.972676Z",
     "iopub.status.idle": "2025-01-03T00:56:33.522921Z",
     "shell.execute_reply": "2025-01-03T00:56:33.521556Z",
     "shell.execute_reply.started": "2025-01-03T00:56:32.973035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_seasonality(train_df_imputed, \"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:33.525117Z",
     "iopub.status.busy": "2025-01-03T00:56:33.524655Z",
     "iopub.status.idle": "2025-01-03T00:56:34.056028Z",
     "shell.execute_reply": "2025-01-03T00:56:34.054808Z",
     "shell.execute_reply.started": "2025-01-03T00:56:33.525074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_seasonality(train_df_imputed, \"day_of_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:34.057901Z",
     "iopub.status.busy": "2025-01-03T00:56:34.057559Z",
     "iopub.status.idle": "2025-01-03T00:56:41.486702Z",
     "shell.execute_reply": "2025-01-03T00:56:41.485543Z",
     "shell.execute_reply.started": "2025-01-03T00:56:34.05787Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_seasonality(train_df_imputed, \"day_of_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We required 2 forecasts:\n",
    "\n",
    "1. **Total Sales** Forecast\n",
    "2. **Product Sales Ratio** Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Total Sales Forecast**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets revist the graph of sales we wish to forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:56:41.488629Z",
     "iopub.status.busy": "2025-01-03T00:56:41.488196Z",
     "iopub.status.idle": "2025-01-03T00:56:42.091057Z",
     "shell.execute_reply": "2025-01-03T00:56:42.089848Z",
     "shell.execute_reply.started": "2025-01-03T00:56:41.488586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data = train_df_imputed, x=\"date\", y=\"num_sold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T01:02:54.773052Z",
     "iopub.status.busy": "2025-01-03T01:02:54.772654Z",
     "iopub.status.idle": "2025-01-03T01:02:54.787268Z",
     "shell.execute_reply": "2025-01-03T01:02:54.785922Z",
     "shell.execute_reply.started": "2025-01-03T01:02:54.773019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#get the dates to forecast for\n",
    "test_total_sales_df = test_df.groupby([\"date\"])[\"id\"].first().reset_index().drop(columns=\"id\")\n",
    "#keep dates for later\n",
    "test_total_sales_dates = test_total_sales_df[[\"date\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a bit of feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T01:02:55.461252Z",
     "iopub.status.busy": "2025-01-03T01:02:55.46072Z",
     "iopub.status.idle": "2025-01-03T01:02:55.481551Z",
     "shell.execute_reply": "2025-01-03T01:02:55.480243Z",
     "shell.execute_reply.started": "2025-01-03T01:02:55.461208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    new_df = df.copy()\n",
    "    new_df[\"month\"] = df[\"date\"].dt.month\n",
    "    new_df[\"month_sin\"] = np.sin(new_df['month'] * (2 * np.pi / 12))\n",
    "    new_df[\"month_cos\"] = np.cos(new_df['month'] * (2 * np.pi / 12))\n",
    "    new_df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    new_df[\"day_of_week\"] = new_df[\"day_of_week\"].apply(lambda x: 0 if x<=3 else(1 if x==4 else (2 if x==5 else (3))))\n",
    "    \n",
    "    new_df[\"day_of_year\"] = df['date'].apply(\n",
    "        lambda x: x.timetuple().tm_yday if not (x.is_leap_year and x.month > 2) else x.timetuple().tm_yday - 1\n",
    "    )\n",
    "    new_df['day_sin'] = np.sin(new_df['day_of_year'] * (2 * np.pi /  365.0))\n",
    "    new_df['day_cos'] = np.cos(new_df['day_of_year'] * (2 * np.pi /  365.0))\n",
    "\n",
    "    #new_df['week_of_year'] = new_df['date'].dt.isocalendar().week\n",
    "    \n",
    "    new_df[\"important_dates\"] = new_df[\"day_of_year\"].apply(lambda x: x if x in [1,2,3,4,5,6,7,8,9,10,99, 100, 101, 125,126,355,256,357,358,359,360,361,362,363,364,365] else 0)\n",
    "    new_df[\"year\"] = df[\"date\"].dt.year - 2010\n",
    "    \n",
    "    new_df = new_df.drop(columns=[\"date\",\"month\",\"day_of_year\"])\n",
    "    new_df = pd.get_dummies(new_df, columns = [\"important_dates\",\"day_of_week\"], drop_first=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T01:02:55.751958Z",
     "iopub.status.busy": "2025-01-03T01:02:55.750719Z",
     "iopub.status.idle": "2025-01-03T01:02:55.818742Z",
     "shell.execute_reply": "2025-01-03T01:02:55.817517Z",
     "shell.execute_reply.started": "2025-01-03T01:02:55.751904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_total_sales_df = feature_engineer(train_df_imputed)\n",
    "test_total_sales_df = feature_engineer(test_total_sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T01:03:02.9197Z",
     "iopub.status.busy": "2025-01-03T01:03:02.919301Z",
     "iopub.status.idle": "2025-01-03T01:03:02.955373Z",
     "shell.execute_reply": "2025-01-03T01:03:02.954022Z",
     "shell.execute_reply.started": "2025-01-03T01:03:02.919668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display(train_total_sales_df.head(2))\n",
    "display(test_total_sales_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:37:52.604246Z",
     "iopub.status.busy": "2025-01-03T00:37:52.603751Z",
     "iopub.status.idle": "2025-01-03T00:37:52.613018Z",
     "shell.execute_reply": "2025-01-03T00:37:52.611742Z",
     "shell.execute_reply.started": "2025-01-03T00:37:52.604198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y = train_total_sales_df[\"num_sold\"]\n",
    "X = train_total_sales_df.drop(columns=\"num_sold\")\n",
    "X_test = test_total_sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and fit the model, then make the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:37:52.614749Z",
     "iopub.status.busy": "2025-01-03T00:37:52.614414Z",
     "iopub.status.idle": "2025-01-03T00:37:52.672958Z",
     "shell.execute_reply": "2025-01-03T00:37:52.671502Z",
     "shell.execute_reply.started": "2025-01-03T00:37:52.61472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Ridge(tol=1e-2, max_iter=1000000, random_state=0)\n",
    "model.fit(X, y)\n",
    "preds = model.predict(X_test)\n",
    "test_total_sales_dates[\"num_sold\"] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:37:52.675324Z",
     "iopub.status.busy": "2025-01-03T00:37:52.674662Z",
     "iopub.status.idle": "2025-01-03T00:37:53.420328Z",
     "shell.execute_reply": "2025-01-03T00:37:53.418995Z",
     "shell.execute_reply.started": "2025-01-03T00:37:52.67526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data = pd.concat([train_df_imputed,test_total_sales_dates]).reset_index(drop=True), x=\"date\", y=\"num_sold\", linewidth=0.6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forecast looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Product Ratio Forecast**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to forecast the sales ratio between products for 2017, 2018 and 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The period of the product ratio sinsidual curves appear to be 2 years. So to forecast 2017 and 2019 I use the 2015 data and to forecast 2018 I use the 2014 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:37:53.422534Z",
     "iopub.status.busy": "2025-01-03T00:37:53.422074Z",
     "iopub.status.idle": "2025-01-03T00:37:53.448759Z",
     "shell.execute_reply": "2025-01-03T00:37:53.447566Z",
     "shell.execute_reply.started": "2025-01-03T00:37:53.422495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "product_ratio_2017_df = product_ratio_df.loc[product_ratio_df[\"date\"].dt.year == 2015].copy()\n",
    "product_ratio_2018_df = product_ratio_df.loc[product_ratio_df[\"date\"].dt.year == 2016].copy()\n",
    "product_ratio_2019_df = product_ratio_df.loc[product_ratio_df[\"date\"].dt.year == 2015].copy()\n",
    "\n",
    "product_ratio_2017_df[\"date\"] = product_ratio_2017_df[\"date\"] + pd.DateOffset(years=2)\n",
    "product_ratio_2018_df[\"date\"] = product_ratio_2018_df[\"date\"] + pd.DateOffset(years=2)\n",
    "product_ratio_2019_df[\"date\"] =  product_ratio_2019_df[\"date\"] + pd.DateOffset(years=4)\n",
    "\n",
    "forecasted_ratios_df = pd.concat([product_ratio_2017_df, product_ratio_2018_df, product_ratio_2019_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:37:53.451205Z",
     "iopub.status.busy": "2025-01-03T00:37:53.450729Z",
     "iopub.status.idle": "2025-01-03T00:37:54.921478Z",
     "shell.execute_reply": "2025-01-03T00:37:54.920363Z",
     "shell.execute_reply.started": "2025-01-03T00:37:53.451162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temp_df = pd.concat([product_ratio_df,forecasted_ratios_df]).reset_index(drop=True)\n",
    "f,ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data=temp_df, x=\"date\", y=\"ratios\", hue=\"product\");\n",
    "ax.axvline(pd.to_datetime(\"2017-01-01\"), color='black', linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Disaggregating Total Sales Forecast**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our two required forecasts, we need to divide the total sales forecast between the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:37:54.923689Z",
     "iopub.status.busy": "2025-01-03T00:37:54.922782Z",
     "iopub.status.idle": "2025-01-03T00:37:55.050347Z",
     "shell.execute_reply": "2025-01-03T00:37:55.049211Z",
     "shell.execute_reply.started": "2025-01-03T00:37:54.923656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Adding in the store ratios\n",
    "store_weights_df = store_weights.reset_index()\n",
    "test_sub_df = pd.merge(test_df, test_total_sales_dates, how=\"left\", on=\"date\")\n",
    "test_sub_df = test_sub_df.rename(columns = {\"num_sold\":\"day_num_sold\"})\n",
    "# Adding in the product ratios\n",
    "test_sub_df = pd.merge(test_sub_df, store_weights_df, how=\"left\", on=\"store\")\n",
    "test_sub_df = test_sub_df.rename(columns = {\"num_sold\":\"store_ratio\"})\n",
    "# Adding in the country ratios\n",
    "test_sub_df[\"year\"] = test_sub_df[\"date\"].dt.year\n",
    "test_sub_df = pd.merge(test_sub_df, gdp_per_capita_filtered_ratios_df_2, how=\"left\", on=[\"year\", \"country\"])\n",
    "test_sub_df = test_sub_df.rename(columns = {\"ratio\":\"country_ratio\"})\n",
    "# Adding in the product ratio\n",
    "test_sub_df = pd.merge(test_sub_df, forecasted_ratios_df, how=\"left\", on=[\"date\", \"product\"])\n",
    "test_sub_df = test_sub_df.rename(columns = {\"ratios\":\"product_ratio\"})\n",
    "\n",
    "# Disaggregating the forecast\n",
    "test_sub_df[\"num_sold\"] = test_sub_df[\"day_num_sold\"] * test_sub_df[\"store_ratio\"] * test_sub_df[\"country_ratio\"] * test_sub_df[\"product_ratio\"]\n",
    "test_sub_df[\"num_sold\"] = test_sub_df[\"num_sold\"].round()\n",
    "display(test_sub_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets visualise the forecasts for all countries, products and stores, to check everything looks okay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:37:55.052317Z",
     "iopub.status.busy": "2025-01-03T00:37:55.05184Z",
     "iopub.status.idle": "2025-01-03T00:38:10.683475Z",
     "shell.execute_reply": "2025-01-03T00:38:10.682367Z",
     "shell.execute_reply.started": "2025-01-03T00:37:55.052275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_all(pd.concat([original_train_df_imputed,test_sub_df]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:38:10.685686Z",
     "iopub.status.busy": "2025-01-03T00:38:10.68537Z",
     "iopub.status.idle": "2025-01-03T00:38:10.694607Z",
     "shell.execute_reply": "2025-01-03T00:38:10.692997Z",
     "shell.execute_reply.started": "2025-01-03T00:38:10.685658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_individual_ts(df):\n",
    "    for country in df[\"country\"].unique():\n",
    "        f,axes = plt.subplots(df[\"store\"].nunique()*df[\"product\"].nunique(),figsize=(20,70))\n",
    "        count = 0\n",
    "        for store in df[\"store\"].unique():\n",
    "            for product in df[\"product\"].unique():\n",
    "                plot_df = df.loc[(df[\"product\"] == product) & (df[\"country\"] == country) & (df[\"store\"] == store)]\n",
    "                sns.lineplot(data = plot_df, x=\"date\", y=\"num_sold\", linewidth=0.5, ax=axes[count])\n",
    "                axes[count].set_title(f\"{country} - {store} - {product}\")\n",
    "                axes[count].axvline(pd.to_datetime(\"2017-01-01\"), color='black', linestyle='--');\n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:38:10.696568Z",
     "iopub.status.busy": "2025-01-03T00:38:10.696211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_individual_ts(pd.concat([original_train_df_imputed,test_sub_df]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"/kaggle/input/playground-series-s5e1/sample_submission.csv\")\n",
    "submission[\"num_sold\"] = test_sub_df[\"num_sold\"]\n",
    "display(submission.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:03:04.511867Z",
     "iopub.status.busy": "2025-01-02T21:03:04.511369Z",
     "iopub.status.idle": "2025-01-02T21:03:04.694329Z",
     "shell.execute_reply": "2025-01-02T21:03:04.693165Z",
     "shell.execute_reply.started": "2025-01-02T21:03:04.511824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10652996,
     "sourceId": 85723,
     "sourceType": "competition"
    },
    {
     "datasetId": 2007861,
     "sourceId": 3325325,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30235,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
